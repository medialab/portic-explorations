{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de match des produits navigo / toflit \n",
    "(tests faits avec 2 classifications toflit : orthographic normalization et simplification ==> résultats pour les 2 tests à la fin)\n",
    "\n",
    "**Procédure :**\n",
    "- créer des listes de produits de plus en plus proches typographiquement [étapes 1 à 3]\n",
    "- pour les noms de produits qui ne trouvent pas de match à la fin, on racinise les nomes de produits (stemming) et on utilise des fonctions de similarité pour proposer des termes similaires (candidats au match) [étapes 4 & 5]\n",
    "\n",
    "0. definition de fonctions \n",
    "1. extraction des produits \n",
    "2. modifications successives des noms de produits \n",
    "3. test des correspondances entre noms de produits nettoyés => obtention de matchs évidents\n",
    "4. racinisation pour les produits qui n'ont toujours pas trouvé de match\n",
    "5. fonction de similarité jaccard pour proposer des matchs moins évidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bootstraping du client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# import the lib client\n",
    "from lib.client import Api\n",
    "# instantiate the lib client\n",
    "client = Api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. definition de fonctions (intersection et différence entre listes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection pour les listes (complexité en O(n))\n",
    "def hybrid_intersection(lst1, lst2):  \n",
    "    temp = set(lst2) \n",
    "    lst3 = [value for value in lst1 if value in temp] \n",
    "    return lst3 \n",
    "\n",
    "# différence entre deux listes\n",
    "def Diff(li1, li2):\n",
    "    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2]\n",
    "    return li_dif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. extraction des produits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de classifications navigo : 124\n",
      "Nombre de classifications trouvées :  28353\n",
      "Nombre de classifications trouvées :  20868\n"
     ]
    }
   ],
   "source": [
    "transfo_names_products_navigo = []\n",
    "with open('dumps/20210208 - cargo dir La Rochelle 08-02-2021.xlsx - id et standardized FR et GB.csv', newline='') as csvfile:\n",
    "    csv_file = csv.reader(csvfile, quotechar='|')\n",
    "    k = 0 # compteur pour savoir à quelle ligner on en est\n",
    "    for row in csv_file:\n",
    "        k += 1\n",
    "        if k == 1: \n",
    "            continue # on ne veut pas mettre le nom des colonnes dans les produits\n",
    "        if k == 126:\n",
    "            break # les noms de produits à partir de la ligne 125 ne sont pas à prendre en compte\n",
    "        transfo_names_products_navigo.append({'navigo_product_id' : row[0], 'name_navigo' : row[1],})\n",
    "print (\"Nombre de classifications navigo :\", len(transfo_names_products_navigo))\n",
    "# print(\"toflit orthographic objects:\",transfo_names_products_navigo)\n",
    "\n",
    "result1 = client.toflit.get_classification_search(\"product_orthographic\")\n",
    "result2 = client.toflit.get_classification_search(\"product_simplification\")\n",
    "\n",
    "transfo_names_products_toflit_orthographic = []\n",
    "for s in result1:         \n",
    "    transfo_names_products_toflit_orthographic.append({'name_toflit_orthographic' : s[\"name\"]})\n",
    "# print(\"toflit orthographic objects:\",transfo_names_products_toflit_orthographic[0:10])\n",
    "    \n",
    "transfo_names_products_toflit_simplification = []\n",
    "for s in result2:          \n",
    "    transfo_names_products_toflit_simplification.append({'name_toflit_simplification' : s[\"name\"]}) \n",
    "# print(\"toflit simplification objects:\",transfo_names_products_toflit_simplification[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. modifications successives des noms de produits enregistrées dans des dictionnaires, et dans des listes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode, fog\n",
    "from fog.key import fingerprint, create_fingerprint\n",
    "f = create_fingerprint(stopwords=['de','du','des','d\\'', 'd','en','à', 'a', 'au','le','la','les','l\\'', 'l', 'et', 'pour', 'un', 'une']) # au niveau des apostrophes : l' et d' ne fonctionnent pas\n",
    "\n",
    "navigo_fingerprinted = []\n",
    "for i in transfo_names_products_navigo:\n",
    "    i['lowercase_name'] = i['name_navigo'].lower()\n",
    "    i['typographic_cleaned_name'] = unidecode.unidecode(i['lowercase_name'])\n",
    "    i['special_charachters_cleaned_name'] = i['typographic_cleaned_name'].replace(\",\",\"\").replace(\";\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"-\",\" \").replace(\"'\",\" \")\n",
    "    i['stop_words_cleaned_name'] = f(fingerprint(i['special_charachters_cleaned_name']))\n",
    "    navigo_fingerprinted.append(i['stop_words_cleaned_name'])\n",
    "# print(\"navigo objects:\",transfo_names_products_navigo)\n",
    "\n",
    "simplification_fingerprinted = []\n",
    "for i in transfo_names_products_toflit_simplification:\n",
    "    i['lowercase_name'] = i['name_toflit_simplification'].lower()\n",
    "    i['typographic_cleaned_name'] = unidecode.unidecode(i['lowercase_name'])\n",
    "    i['special_charachters_cleaned_name'] = i['typographic_cleaned_name'].replace(\",\",\"\").replace(\";\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"-\",\" \").replace(\"'\",\" \")\n",
    "    i['stop_words_cleaned_name'] = f(fingerprint(i['special_charachters_cleaned_name']))\n",
    "    simplification_fingerprinted.append(i['stop_words_cleaned_name'])\n",
    "# print(\"toflit simplification objects:\",transfo_names_products_toflit_simplification[0:30])\n",
    "\n",
    "orthographic_fingerprinted = []\n",
    "for i in transfo_names_products_toflit_orthographic:\n",
    "    i['lowercase_name'] = i['name_toflit_orthographic'].lower()\n",
    "    i['typographic_cleaned_name'] = unidecode.unidecode(i['lowercase_name'])\n",
    "    i['special_charachters_cleaned_name'] = i['typographic_cleaned_name'].replace(\",\",\"\").replace(\";\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"-\",\" \").replace(\"'\",\" \")\n",
    "    i['stop_words_cleaned_name'] = f(fingerprint(i['special_charachters_cleaned_name']))\n",
    "    orthographic_fingerprinted.append(i['stop_words_cleaned_name'])\n",
    "# print(\"toflit orthographic objects:\",transfo_names_products_toflit_orthographic[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. test des correspondances entre noms de produits nettoyés\n",
    "à ce stade les noms de produits sont tous en minuscule, standardisés typographiquement, sans caractères spéciaux et sans stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ********************** Correspondance noms de produits néttoyés **********************\n",
      "elements communs navigo / toflit orthographic : 95\n",
      "elements communs navigo / toflit simplification : 93\n",
      "\n",
      "navigo / toflit orthographic ; reste à aligner à la main  29  produits :  ['soude', 'biscuits', 'ail', 'voiles', 'graines lin', 'bois merrain', 'marchandises naufrage', 'bretagne pressees sardines', 'grain', 'fourrage', 'pierre taille', 'cordages vieux', 'canon poudre', 'feuillard', 'echalotte', 'meture', 'tuilles', 'ardoises', 'broue terre verrerie', 'grements navire', 'meule moulin', 'moulin verge', 'frais moules peche poisson', 'vesces', 'etoupe', 'marchandises negriere traite', 'casse verre', 'turbe', 'bois copeaux pieces']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n ********************** Correspondance noms de produits néttoyés **********************\")\n",
    "               \n",
    "common_navigo_ortho = hybrid_intersection(navigo_fingerprinted, orthographic_fingerprinted)\n",
    "common_navigo_simpli = hybrid_intersection(navigo_fingerprinted, simplification_fingerprinted)\n",
    "print(\"elements communs navigo / toflit orthographic :\", len(common_navigo_ortho))\n",
    "print(\"elements communs navigo / toflit simplification :\", len(common_navigo_simpli))\n",
    "\n",
    "# Visualisation de ce qui reste à aligner (on décide de procéder avec la convention orthographic simplification)\n",
    "a_aligner_simplification = Diff(navigo_fingerprinted, common_navigo_simpli)\n",
    "a_aligner_orthographic = Diff(navigo_fingerprinted, common_navigo_ortho)\n",
    "\n",
    "# print(\"\\nnavigo / toflit simplification ; reste à aligner à la main \", len(a_aligner_simplification), \" produits : \", a_aligner_simplification)\n",
    "print(\"\\nnavigo / toflit orthographic ; reste à aligner à la main \", len(a_aligner_orthographic), \" produits : \", a_aligner_orthographic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export des matchs évidents dans un fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# écriture des matchs au format csv\n",
    "\n",
    "with open('dumps/product_matching/easy_match_navigo_toflitsimplification.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['matching_stop_words_cleaned_name', 'navigo_product_id', 'name_navigo', 'product_toflitsimplification']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for i in transfo_names_products_navigo:\n",
    "            for j in transfo_names_products_toflit_simplification:\n",
    "                \n",
    "                if i['stop_words_cleaned_name'] == j['stop_words_cleaned_name']: # it's a match !\n",
    "                    writer.writerow({'matching_stop_words_cleaned_name' : i['stop_words_cleaned_name'], 'navigo_product_id': i['navigo_product_id'], 'name_navigo': i['name_navigo'], 'product_toflitsimplification': j['name_toflit_simplification']})\n",
    "\n",
    "with open('dumps/product_matching/easy_match_navigo_toflitorthographic.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['matching_stop_words_cleaned_name', 'navigo_product_id', 'name_navigo', 'product_toflitorthographic']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for i in transfo_names_products_navigo:\n",
    "            for j in transfo_names_products_toflit_orthographic:\n",
    "                \n",
    "                if i['stop_words_cleaned_name'] == j['stop_words_cleaned_name']: # it's a match !\n",
    "                    writer.writerow({'matching_stop_words_cleaned_name' : i['stop_words_cleaned_name'], 'navigo_product_id': i['navigo_product_id'], 'name_navigo': i['name_navigo'], 'product_toflitorthographic': j['name_toflit_orthographic']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. racinisation (stemming) : pour les produits qui n'ont toujours pas trouvé de match, on remonte à leur radical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"french\") # choix du language\n",
    "\n",
    "transfo_names_products_navigo_for_ortho = transfo_names_products_navigo # copie car on a besoin de 2 structures qui évoluent indépendamment en fonction de si on veut fonctionner avec orthographic ou simplification à partir d'ici\n",
    "\n",
    "for i in transfo_names_products_navigo:\n",
    "    if i['stop_words_cleaned_name'] in a_aligner_simplification: # on racinise les noms des produits restant à aligner (on choisit simplification car c'est ce qui nous donne le plus de produits à aligner, on restreindra pour orthographic)\n",
    "        k=0\n",
    "        stemmed_string=\"\"\n",
    "        for token in word_tokenize(i['stop_words_cleaned_name']): # chaque mot est racinisé (un token par mot)\n",
    "            if (k != 0): # je rajoute des espaces à la main que j'avais perdu avec la tokenisation, il doit y avoir mieux comme manière de faire\n",
    "                stemmed_string = stemmed_string + \" \" \n",
    "            k += 1\n",
    "            stemmed_string += stemmer.stem(token)\n",
    "        i['stemmed_name'] = stemmed_string\n",
    "\"\"\"\n",
    "print(\" -------------------- 10 objets navigo a aligner avec toflit simplification :\")\n",
    "for i in transfo_names_products_navigo[0:10]:\n",
    "    if 'stemmed_name' in i :\n",
    "        print (i)\n",
    "\"\"\"\n",
    "\n",
    "for i in transfo_names_products_navigo_for_ortho:\n",
    "    if i['stop_words_cleaned_name'] in a_aligner_simplification: # on racinise les noms des produits restant à aligner (on choisit simplification car c'est ce qui nous donne le plus de produits à aligner, on restreindra pour orthographic)\n",
    "        k=0\n",
    "        stemmed_string=\"\"\n",
    "        for token in word_tokenize(i['stop_words_cleaned_name']): # chaque mot est racinisé (un token par mot)\n",
    "            if (k != 0): # je rajoute des espaces à la main que j'avais perdu avec la tokenisation, il doit y avoir mieux comme manière de faire\n",
    "                stemmed_string = stemmed_string + \" \" \n",
    "            k += 1\n",
    "            stemmed_string += stemmer.stem(token)\n",
    "        i['stemmed_name'] = stemmed_string\n",
    "\"\"\"\n",
    "print(\" -------------------- 10 objets navigo a aligner avec toflit orthographic :\")\n",
    "for i in transfo_names_products_navigo_for_ortho[0:10]:\n",
    "    if 'stemmed_name' in i :\n",
    "        print (i)\n",
    "\"\"\"\n",
    "\n",
    "for i in transfo_names_products_toflit_simplification:\n",
    "        k=0\n",
    "        stemmed_string=\"\"\n",
    "        for token in word_tokenize(i['stop_words_cleaned_name']):\n",
    "            if (k != 0): \n",
    "                stemmed_string = stemmed_string + \" \" \n",
    "            k += 1\n",
    "            stemmed_string += stemmer.stem(token)\n",
    "        i['stemmed_name'] = stemmed_string\n",
    "# print(\" -------------------- 10 toflit simplification objects:\\n\", transfo_names_products_toflit_simplification[0:10]) \n",
    "\n",
    "for i in transfo_names_products_toflit_orthographic:\n",
    "        k=0\n",
    "        stemmed_string=\"\"\n",
    "        for token in word_tokenize(i['stop_words_cleaned_name']):\n",
    "            if (k != 0): \n",
    "                stemmed_string = stemmed_string + \" \" \n",
    "            k += 1\n",
    "            stemmed_string += stemmer.stem(token)\n",
    "        i['stemmed_name'] = stemmed_string\n",
    "# print(\" -------------------- 10 toflit orthographic objects:\\n\", transfo_names_products_toflit_orthographic[0:10]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. fonction de similarité jaccard pour proposer des matchs moins évidents \n",
    "**choisi comme la solution la plus pertinente ; expérimentalement, seuil d'acceptation fixé à 1 (on veut restreindre au max les faux positifs, mais on en a encore de trop)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ proposition de matchs avec jaccard (navigo / toflit simplification) ***********\n",
      "\n",
      "produit navigo: Diverses marchandises\n",
      "\n",
      "produit navigo: Soude\n",
      "candidat toflit: soudes\n",
      "\n",
      "produit navigo: Biscuits\n",
      "candidat toflit: biscuit\n",
      "\n",
      "produit navigo: Voiles\n",
      "candidat toflit: voile\n",
      "candidat toflit: olives\n",
      "candidat toflit: olivier\n",
      "candidat toflit: viole\n",
      "\n",
      "produit navigo: Graines de lin\n",
      "candidat toflit: graine de lin\n",
      "candidat toflit: grains ails\n",
      "candidat toflit: grains de lin\n",
      "candidat toflit: graine et graine de lin\n",
      "\n",
      "produit navigo: Bois merrain\n",
      "candidat toflit: bois et merrains\n",
      "\n",
      "produit navigo: Marchandises d'un naufrage\n",
      "\n",
      "produit navigo: Pêche des moules\n",
      "\n",
      "produit navigo: Sardines pressées de Bretagne\n",
      "\n",
      "produit navigo: Froment\n",
      "\n",
      "produit navigo: Grain\n",
      "candidat toflit: graine\n",
      "candidat toflit: grains\n",
      "candidat toflit: graine ???\n",
      "candidat toflit: graine de\n",
      "candidat toflit: graine de l ???\n",
      "\n",
      "produit navigo: Résine\n",
      "candidat toflit: résines\n",
      "\n",
      "produit navigo: Fourrage\n",
      "candidat toflit: fourrages\n",
      "\n",
      "produit navigo: Pierre de taille\n",
      "candidat toflit: papier à lettre\n",
      "candidat toflit: papier à litière\n",
      "candidat toflit: papier tellière\n",
      "candidat toflit: pierres de taille\n",
      "candidat toflit: pierres et plâtre\n",
      "candidat toflit: pierres taillées\n",
      "candidat toflit: plâtre de pierres\n",
      "\n",
      "produit navigo: Vieux cordages\n",
      "candidat toflit: cordage de vieux\n",
      "candidat toflit: cordage vieux\n",
      "\n",
      "produit navigo: Poudre à canon\n",
      "candidat toflit: poudre à canons\n",
      "candidat toflit: poudre de canons\n",
      "\n",
      "produit navigo: Bois de chauffage\n",
      "\n",
      "produit navigo: Echalotte\n",
      "candidat toflit: échalote\n",
      "\n",
      "produit navigo: Méture\n",
      "\n",
      "produit navigo: Tuilles\n",
      "candidat toflit: tuiles\n",
      "\n",
      "produit navigo: Terre de Broue [pour verrerie]\n",
      "\n",
      "produit navigo: Gréments de navire\n",
      "\n",
      "produit navigo: Meule de moulin\n",
      "candidat toflit: meules pour moulins\n",
      "candidat toflit: meules pour moulin\n",
      "\n",
      "produit navigo: Verge de moulin\n",
      "candidat toflit: verges à moulins\n",
      "\n",
      "produit navigo: Pêche des moules et du poisson frais\n",
      "\n",
      "produit navigo: Hardes de mer\n",
      "\n",
      "produit navigo: Etoupe\n",
      "candidat toflit: étoupes\n",
      "\n",
      "produit navigo: Marchandises pour la traite négrière\n",
      "\n",
      "produit navigo: Verre cassé\n",
      "candidat toflit: verrerie cassée\n",
      "candidat toflit: verres cassés\n",
      "\n",
      "produit navigo: Turbe\n",
      "candidat toflit: turbit\n",
      "candidat toflit: brut\n",
      "\n",
      "produit navigo: Copeaux et pièces de bois\n",
      "************ proposition de matchs avec jaccard (navigo / toflit orthographic) ***********\n",
      "\n",
      "produit navigo: Diverses marchandises\n",
      "candidat toflit: marchandises diverses\n",
      "candidat toflit: diverses marchandises\n",
      "candidat toflit: diverses marchandises sèches\n",
      "candidat toflit: divers marchandises\n",
      "candidat toflit: marchandises des Indes diverses\n",
      "\n",
      "produit navigo: Soude\n",
      "candidat toflit: soudes\n",
      "\n",
      "produit navigo: Biscuits\n",
      "candidat toflit: biscuit\n",
      "\n",
      "produit navigo: Voiles\n",
      "candidat toflit: olive\n",
      "candidat toflit: voile\n",
      "candidat toflit: olivier\n",
      "candidat toflit: viole\n",
      "\n",
      "produit navigo: Graines de lin\n",
      "candidat toflit: graine de lin\n",
      "candidat toflit: graine lin\n",
      "candidat toflit: grains de lin\n",
      "candidat toflit: grains ails\n",
      "\n",
      "produit navigo: Bois merrain\n",
      "candidat toflit: bois merrains\n",
      "candidat toflit: bois de merrains\n",
      "candidat toflit: bois en merrains\n",
      "candidat toflit: bois et merrains\n",
      "candidat toflit: bois merrains ???\n",
      "candidat toflit: bois merrains merrains\n",
      "\n",
      "produit navigo: Marchandises d'un naufrage\n",
      "\n",
      "produit navigo: Pêche des moules\n",
      "candidat toflit: pêche des moules\n",
      "\n",
      "produit navigo: Sardines pressées de Bretagne\n",
      "\n",
      "produit navigo: Froment\n",
      "candidat toflit: froment\n",
      "\n",
      "produit navigo: Grain\n",
      "candidat toflit: grains\n",
      "candidat toflit: graine\n",
      "candidat toflit: graine de l ???\n",
      "candidat toflit: graine ?\n",
      "candidat toflit: graine de\n",
      "candidat toflit: graine ???\n",
      "\n",
      "produit navigo: Résine\n",
      "candidat toflit: résines\n",
      "candidat toflit: résiné\n",
      "\n",
      "produit navigo: Fourrage\n",
      "candidat toflit: fourrages\n",
      "\n",
      "produit navigo: Pierre de taille\n",
      "candidat toflit: papier à lettres\n",
      "candidat toflit: pierres de taille\n",
      "candidat toflit: papier à lettre\n",
      "candidat toflit: papier tellière\n",
      "candidat toflit: pierres taillées\n",
      "candidat toflit: papier à litière\n",
      "candidat toflit: pierres et plâtre\n",
      "candidat toflit: plâtre en pierres\n",
      "\n",
      "produit navigo: Vieux cordages\n",
      "candidat toflit: cordage vieux\n",
      "candidat toflit: cordage de vieux\n",
      "\n",
      "produit navigo: Poudre à canon\n",
      "candidat toflit: poudre à canons\n",
      "candidat toflit: poudre de canons\n",
      "\n",
      "produit navigo: Bois de chauffage\n",
      "candidat toflit: bois de chauffage\n",
      "\n",
      "produit navigo: Echalotte\n",
      "candidat toflit: échalotes\n",
      "\n",
      "produit navigo: Méture\n",
      "\n",
      "produit navigo: Tuilles\n",
      "candidat toflit: tuiles\n",
      "\n",
      "produit navigo: Terre de Broue [pour verrerie]\n",
      "\n",
      "produit navigo: Gréments de navire\n",
      "\n",
      "produit navigo: Meule de moulin\n",
      "candidat toflit: meules à moulins\n",
      "candidat toflit: meules de moulins\n",
      "candidat toflit: meules à moulin\n",
      "candidat toflit: meules moulins\n",
      "candidat toflit: meules pour moulins\n",
      "\n",
      "produit navigo: Verge de moulin\n",
      "candidat toflit: verges à moulins\n",
      "\n",
      "produit navigo: Pêche des moules et du poisson frais\n",
      "\n",
      "produit navigo: Hardes de mer\n",
      "candidat toflit: hardes de mer\n",
      "\n",
      "produit navigo: Etoupe\n",
      "candidat toflit: étoupes\n",
      "\n",
      "produit navigo: Marchandises pour la traite négrière\n",
      "\n",
      "produit navigo: Verre cassé\n",
      "candidat toflit: verres cassés\n",
      "candidat toflit: verrerie cassée\n",
      "candidat toflit: verres d'Asace\n",
      "\n",
      "produit navigo: Turbe\n",
      "candidat toflit: turbit\n",
      "candidat toflit: turbie\n",
      "candidat toflit: brut\n",
      "\n",
      "produit navigo: Copeaux et pièces de bois\n"
     ]
    }
   ],
   "source": [
    "from fog.metrics import jaccard_similarity\n",
    "\n",
    "#1 création de listes qui aggrègent les noms navigos restant à aligner et les propositions de matching avec jaccard\n",
    "proposal_jaccard_simplification = [] \n",
    "proposal_jaccard_simplification_to_csv = [] # nous servira au moment d'exporter les resultats en csv\n",
    "proposal_jaccard_orthographic = [] \n",
    "proposal_jaccard_orthographic_to_csv = []\n",
    "\n",
    "\n",
    "#2 initialisations des listes avec les produits navigo à matcher\n",
    "for i in transfo_names_products_navigo:\n",
    "    if 'stemmed_name' in i : # selection des produits navigo qu'il reste à aligner avec toflit simplification\n",
    "        proposal_jaccard_simplification.append([i]) # on crée une liste de listes qui commencent toujours par l'objet navigo pour lequel on recherche un match\n",
    "        proposal_jaccard_simplification_to_csv.append([i['navigo_product_id'], i['name_navigo']])\n",
    "# print(proposal_jaccard_simplification)\n",
    "\n",
    "for i in transfo_names_products_navigo_for_ortho:\n",
    "    if 'stemmed_name' in i : # selection des produits navigo qu'il reste à aligner avec toflit orthographic\n",
    "        proposal_jaccard_orthographic.append([i]) \n",
    "        proposal_jaccard_orthographic_to_csv.append([i['navigo_product_id'], i['name_navigo']])\n",
    "# print(proposal_jaccard_orthographic)\n",
    "\n",
    "\n",
    "#3 complétion des listes avec les propositions de match\n",
    "for i in proposal_jaccard_simplification: # i est une liste qui contient un objet navigo à aligner\n",
    "    for j in transfo_names_products_toflit_simplification: # j est un objet toflit simplification\n",
    "        if jaccard_similarity(i[0]['stemmed_name'],j['stemmed_name']) == 1:\n",
    "            # je récupère index de i\n",
    "            index = proposal_jaccard_simplification.index(i)\n",
    "            # dans la sous-liste, je mets à la pelle les noms dans toflit simplification qui, cleanés et racinisés sont similaires aux noms navigos\n",
    "            proposal_jaccard_simplification[index].append(j['name_toflit_simplification'])\n",
    "            proposal_jaccard_simplification_to_csv[index].append(j['name_toflit_simplification']) \n",
    "\n",
    "for i in proposal_jaccard_orthographic: \n",
    "    for j in transfo_names_products_toflit_orthographic: \n",
    "        if jaccard_similarity(i[0]['stemmed_name'],j['stemmed_name']) == 1:\n",
    "            index = proposal_jaccard_orthographic.index(i)\n",
    "            proposal_jaccard_orthographic[index].append(j['name_toflit_orthographic'])\n",
    "            proposal_jaccard_orthographic_to_csv[index].append(j['name_toflit_orthographic']) \n",
    "            \n",
    "print(\"************ proposition de matchs avec jaccard (navigo / toflit simplification) ***********\")\n",
    "for i in proposal_jaccard_simplification: # i est une liste\n",
    "    for j in i: # j est un dict, ou un str\n",
    "        if isinstance(j,dict): \n",
    "            print(\"\\nproduit navigo:\", j['name_navigo'])\n",
    "        else:\n",
    "            print(\"candidat toflit:\", j) \n",
    "\n",
    "print(\"\\n\\n************ proposition de matchs avec jaccard (navigo / toflit orthographic) ***********\")\n",
    "for i in proposal_jaccard_orthographic: # i est une liste\n",
    "    for j in i: # j est un dict, ou un str\n",
    "        if isinstance(j,dict): \n",
    "            print(\"\\nproduit navigo:\", j['name_navigo'])\n",
    "        else:\n",
    "            print(\"candidat toflit:\", j) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Si on veut exporter les propositions de match permis par la similarité jaccard dans un fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# écriture des propositions de matchs au format csv (1ere colonne : id navigo, 2e : nom navigo, colonnes suivantes : propositions de match chez toflit trouvées par jaccard)\n",
    "with open('dumps/product_matching/jaccard_match_proposal_navigo_toflitsimplification.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['navigo_product_id', 'name_navigo', 'proposals_toflitsimplification'])\n",
    "            writer.writerows(proposal_jaccard_simplification_to_csv)\n",
    "\n",
    "with open('dumps/product_matching/jaccard_match_proposal_navigo_toflitorthographic.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['navigo_product_id', 'name_navigo', 'proposals_toflitorthographic'])\n",
    "            writer.writerows(proposal_jaccard_orthographic_to_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liens vers mes résultats\n",
    "\n",
    "**Alignement navigo / toflit orthographic :**\n",
    "- easy matching https://docs.google.com/spreadsheets/d/1RLVLy6M23HWRZ5ol88V1wQaDXQEIgePZRRXlk5825v4/edit?usp=sharing\n",
    "- propositions de matching avec jaccard https://docs.google.com/spreadsheets/d/1b38GkQgNE3wn4pW0XjeT2c3Iuy5asgawHZVtcwq9HNQ/edit?usp=sharing\n",
    "\n",
    "**Alignement navigo / toflit simplification :**\n",
    "- easy matching : https://docs.google.com/spreadsheets/d/1rSh9MUqYS2SVURNc0M29m2Ml2TXksqwIY7ZVG5Gfs2o/edit?usp=sharing\n",
    "- propositions de matching avec jaccard : https://docs.google.com/spreadsheets/d/18MNbLV0zNcE26LbVPsbCF6r_avi_tFpCnaLIEB7iCMg/edit?usp=sharing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests infructueux avec d'autres fonctions de similarité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'name_toflit_simplification'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-42175d8be335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdice_coefficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stemmed_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stemmed_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproposal_dice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mproposal_dice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name_toflit_simplification'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproposal_overlap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'name_toflit_simplification'"
     ]
    }
   ],
   "source": [
    "from fog.metrics import dice_coefficient, overlap_coefficient\n",
    "from nltk import edit_distance\n",
    "\n",
    "# pas de résultats satisfaisants avec ces techniques pour l'instant\n",
    "proposal_dice = []\n",
    "for i in transfo_names_products_navigo:\n",
    "    if 'stemmed_name' in i :\n",
    "        proposal_dice.append([i])\n",
    "# print(proposal_dice)\n",
    "\n",
    "proposal_overlap = []\n",
    "for i in transfo_names_products_navigo:\n",
    "    if 'stemmed_name' in i :\n",
    "        proposal_overlap.append([i]) \n",
    "# print(proposal_overlap)\n",
    "\n",
    "proposal_levenshtein = []\n",
    "for i in transfo_names_products_navigo:\n",
    "    if 'stemmed_name' in i :\n",
    "        proposal_levenshtein.append([i]) \n",
    "# print(proposal_levenshtein)\n",
    "\n",
    "for i in proposal_dice:\n",
    "        if dice_coefficient(i[0]['stemmed_name'],j['stemmed_name']) >= 0.6:\n",
    "            index = proposal_dice.index(i)\n",
    "            proposal_dice[index].append(j['name_toflit_simplification'])\n",
    "\n",
    "for i in proposal_overlap:\n",
    "        if overlap_coefficient(i[0]['stemmed_name'],j['stemmed_name']) >= 0.6:\n",
    "            index = proposal_overlap.index(i)\n",
    "            proposal_overlap[index].append(j['name_toflit_simplification'])\n",
    "            \n",
    "for i in proposal_levenshtein:       \n",
    "        if edit_distance(i[0]['stemmed_name'],j['stemmed_name']) <= 60:\n",
    "            index = proposal_levenshtein.index(i)\n",
    "            proposal_levenshtein[index].append(j['name_toflit_simplification'])\n",
    "            \n",
    "print(\"\\n\\n************ proposal dice ***********\")\n",
    "for i in proposal_dice: \n",
    "    for j in i: \n",
    "        if isinstance(j,dict): \n",
    "            print(\"\\nproduit navigo:\", j['name_navigo'])\n",
    "        else:\n",
    "            print(\"candidat toflit:\", j) \n",
    "\n",
    "print(\"\\n\\n************ proposal overlap ***********\")\n",
    "for i in proposal_overlap: \n",
    "    for j in i: \n",
    "        if isinstance(j,dict): \n",
    "            print(\"\\nproduit navigo:\", j['name_navigo'])\n",
    "        else:\n",
    "            print(\"candidat toflit:\", j) \n",
    "\n",
    "print(\"\\n\\n************ proposal levenshtein ***********\")\n",
    "for i in proposal_levenshtein: \n",
    "    for j in i: \n",
    "        if isinstance(j,dict): \n",
    "            print(\"\\nproduit navigo:\", j['name_navigo'])\n",
    "        else:\n",
    "            print(\"candidat toflit:\", j) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
